{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Preprocessing the publications data and members' stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install the library.\n",
    "# %pip install scholarmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries.\n",
    "import csv, pandas as pd, numpy as np, os\n",
    "from scholarmetrics import hindex, gindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the \"prepared\" directory.\n",
    "os.makedirs(\"../data/prepared/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting and checking the information dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data.\n",
    "df_data = pd.read_csv(\"../data/raw/manuscripts_group.csv\", delimiter=\",\", header=0,\n",
    "    dtype={\"id\": str, \"pubmed_id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the data.\n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking some information about the data.\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the first five records.\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Members' data and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Members' data.\n",
    "df_members = pd.read_csv(\"../data/raw/members_stats.csv\", delimiter=\",\", header=0,\n",
    "    dtype={\"id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking some information about the data.\n",
    "df_members.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the first five records.\n",
    "df_members.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Members' data and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the records of a feature.\n",
    "def normalize_feature(row):\n",
    "    if row:\n",
    "        fields = list(row[0].keys())\n",
    "        records = set([tuple([item[k] for k in fields]) for item in row])\n",
    "        row = tuple([dict(zip(fields, item)) for item in records])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing \"NaN\" values by \"None\" ones.\n",
    "df_members.replace({np.nan: None}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary columns of Members' data.\n",
    "columns_deleted = [\"initials\", \"surname\", \"indexed_name\", \"given_name\", \"eid\", \"list_eids_documents\"]\n",
    "df_members.drop(axis=1, columns=columns_deleted, inplace=True)\n",
    "df_members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from the \"str\" type to the \"list\" type of some columns of Members data.\n",
    "df_members.orcid = df_members.orcid.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_members.identifiers = df_members.identifiers.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_members.subject_areas = df_members.subject_areas.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_members.publication_range = df_members.publication_range.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_members.affiliation_current = df_members.affiliation_current.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_members.affiliation_history = df_members.affiliation_history.apply(lambda x: eval(x) if not pd.isnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the features \"subject_areas\" and \"affiliation_history\".\n",
    "df_members.subject_areas = df_members.subject_areas.apply(normalize_feature)\n",
    "df_members.affiliation_history = df_members.affiliation_history.apply(normalize_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the research line for each member.\n",
    "member_per_research_line = {\n",
    "    \"Automation and Systems\": [\n",
    "        \"ANDRÉ LAURINDO MAITELLI\",\n",
    "        \"ANDRES ORTIZ SALAZAR\",\n",
    "        \"CARLOS EDUARDO TRABUCO DOREA\",\n",
    "        \"DIOMADSON RODRIGUES BELFORT\",\n",
    "        \"FABIO MENEGHETTI UGULINO DE ARAUJO\",\n",
    "        \"FLAVIO BEZERRA COSTA\",\n",
    "        \"MANOEL FIRMINO DE MEDEIROS JUNIOR\",\n",
    "        \"RICARDO LUCIO DE ARAUJO RIBEIRO\",\n",
    "        \"SEBASTIAN YURI CAVALCANTI CATUNDA\",\n",
    "        \"WALLACE MOREIRA BESSA\"],\n",
    "\n",
    "    \"Computer Engineering\": [\n",
    "        \"ADRIAO DUARTE DORIA NETO\",\n",
    "        \"ALLAN DE MEDEIROS MARTINS\",\n",
    "        \"DANIEL ALOISE\",\n",
    "        \"IVANOVITCH MEDEIROS DANTAS DA SILVA\",\n",
    "        \"LUIZ AFFONSO HENDERSON GUEDES DE OLIVEIRA\",\n",
    "        \"LUIZ FELIPE DE QUEIROZ SILVEIRA\",\n",
    "        \"LUIZ MARCOS GARCIA GONCALVES\",\n",
    "        \"MARCELO AUGUSTO COSTA FERNANDES\",\n",
    "        \"PABLO JAVIER ALSINA\",\n",
    "        \"RICARDO ALEXSANDRO DE MEDEIROS VALENTIM\",\n",
    "        \"SAMUEL XAVIER DE SOUZA\"],\n",
    "\n",
    "    \"Telecommunication\": [\n",
    "        \"ADAILDO GOMES D'ASSUNCAO\",\n",
    "        \"ANTONIO LUIZ PEREIRA DE SIQUEIRA CAMPOS\",\n",
    "        \"JOSE PATROCINIO DA SILVA\",\n",
    "        \"VALDEMIR PRAXEDES DA SILVA NETO\",\n",
    "        \"VICENTE ANGELO DE SOUSA JUNIOR\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including the research line for each member and defining the permanent members.\n",
    "for rl, members in member_per_research_line.items():\n",
    "    df_members.loc[[member in members for member in df_members.complete_name], \"research_line\"] = rl\n",
    "    df_members.loc[[member in members for member in df_members.complete_name], \"is_permanent\"] = True\n",
    "df_members.loc[df_members.research_line.isnull(), \"research_line\"] = None\n",
    "df_members[\"is_permanent\"].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the affiliations of the authors.\n",
    "def normalize_affiliations(row):\n",
    "    # Getting missing values within \"author_affil\" feature from \"affiliations\" one.\n",
    "    if row.affiliations and row.author_affil:\n",
    "        for pos, author in enumerate(row.author_affil):\n",
    "            for affil in row.affiliations:\n",
    "                if str(affil[\"id\"]) and str(author[\"affil_id\"]) and str(affil[\"id\"]) in [af.strip()\n",
    "                        for af in str(author[\"affil_id\"]).split(\",\")]:\n",
    "                    row.author_affil[pos][\"affil_id\"] = str(affil[\"id\"])\n",
    "                    row.author_affil[pos][\"affiliation\"] = affil[\"affiliation\"]\n",
    "                    if affil[\"country\"] and not author[\"country\"]:\n",
    "                        row.author_affil[pos][\"country\"] = affil[\"country\"]\n",
    "                    elif affil[\"country\"] != author[\"country\"]:\n",
    "                        row.author_affil[pos][\"country\"] = affil[\"country\"]\n",
    "    else:\n",
    "        # Getting missing values within \"affiliations\" feature from \"author_affil\" one.\n",
    "        if row.author_affil and not row.affiliations:\n",
    "            affils = set([(str(author[\"affil_id\"]), author[\"affiliation\"], author[\"country\"])\n",
    "                        for author in row.author_affil\n",
    "                        if author[\"affil_id\"] or author[\"affiliation\"] or author[\"country\"]])\n",
    "            if len(affils) > 0:\n",
    "                keys = [\"id\", \"affiliation\", \"country\"]\n",
    "                row.affiliations = tuple([dict(zip(keys, affil)) for affil in affils])\n",
    "            else:\n",
    "                row.affiliations = None\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the name of the authors.\n",
    "def normalize_name_authors(row):\n",
    "    if row.authors and row.author_affil:\n",
    "        for pos, item in enumerate(row.authors):\n",
    "            for author in list(row.author_affil):\n",
    "                if str(item[\"id\"]) == str(author[\"id\"]):\n",
    "                    row.authors[pos][\"name\"] = author[\"name\"]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the the authors and their affiliations.\n",
    "def normalize_features(row):\n",
    "    fields = {\n",
    "        \"authors\": [\"id\", \"name\"],\n",
    "        \"affiliations\": [\"id\", \"affiliation\", \"country\"],\n",
    "        \"affil\": [\"affil_id\", \"affiliation\", \"country\"]\n",
    "    }\n",
    "    # Normalizing the authors.\n",
    "    records = [tuple([item[f] for f in fields[\"authors\"]]) for item in row.authors]\n",
    "    if row.author_affil:\n",
    "        records = set([*records, *[tuple([item[c] for c in fields[\"authors\"]])\n",
    "                                    for item in row.author_affil]])\n",
    "    row.authors = tuple([dict(zip(fields[\"authors\"], auth)) for auth in records])\n",
    "\n",
    "    # Normalizing the affiliations.\n",
    "    if row.affiliations:\n",
    "        records = [tuple([item[c] for c in fields[\"affiliations\"]])\n",
    "                for item in row.affiliations]\n",
    "        if row.author_affil:\n",
    "            records = set([*records, *[tuple([item[c] for c in fields[\"affil\"]])\n",
    "                                    for item in row.author_affil]])\n",
    "        row.affiliations = tuple([dict(zip(fields[\"affiliations\"], affil))\n",
    "                                for affil in records])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the ID of some features.\n",
    "def normalize_id_features(row):\n",
    "    fields = [\"id\", \"code\", \"affil_id\"]\n",
    "    features = row.index.tolist()\n",
    "    for f in features:\n",
    "        if pd.notnull(row[f]):\n",
    "            row[f] = tuple([{k: str(item[k]) if k in fields else item[k] for k in item} for item in row[f]])\n",
    "        else:\n",
    "            row[f] = None\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the Scopus IDs of some articles.\n",
    "ids = [\"2-s2.0-85126083408\", \"2-s2.0-85112304772\", \"2-s2.0-85126284305\", \"2-s2.0-85110504864\"]\n",
    "df_data.id[df_data.id.isin(ids)] = df_data.id[df_data.id.isin(ids)].apply(lambda x: x.replace(\"2-s2.0-\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the existence of invalid records.\n",
    "df_data[df_data.id.notnull() & df_data.eid.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the invalid record.\n",
    "df_data = df_data[df_data.id.notnull() & df_data.eid.notnull()]\n",
    "\n",
    "# Checking the result.\n",
    "df_data[df_data.id.notnull() & df_data.eid.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there are duplicates by Scopus id.\n",
    "print(\"Number of duplicated records:\", df_data[df_data.id.duplicated()].id.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicated records.\n",
    "df_data.drop_duplicates(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there are duplicates by Scopus id.\n",
    "print(\"Number of duplicated records:\", df_data[df_data.id.duplicated(keep=False)].id.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the \"vehicle_name\" and \"conference_name\" columns.\n",
    "df_data.loc[df_data.conference_name.notnull() & df_data.vehicle_name.isnull(), \"vehicle_name\"] = df_data.loc[\n",
    "    df_data.conference_name.notnull() & df_data.vehicle_name.isnull(), \"conference_name\"]\n",
    "\n",
    "# Normalizing some values of \"vehicle_name\" column.\n",
    "df_data.loc[df_data.vehicle_name == \"Controle y Automacao\", \"vehicle_name\"] = \"Controle and Automacao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary columns of Production data.\n",
    "columns_deleted = [\"doi\", \"pii\", \"pubmed_id\", \"description\", \"conf_location\", \"conference_name\",\n",
    "                   \"vehicle_address\", \"title_edition\", \"publisher\"]\n",
    "df_data.drop(axis=1, columns=columns_deleted, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the type of \"publication_date\" column.\n",
    "df_data.publication_date = pd.to_datetime(df_data.publication_date, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the type of \"citation_num\" and \"ref_count\" columns.\n",
    "df_data.citation_num = df_data.citation_num.apply(lambda x: int(x) if not pd.isnull(x) else None)\n",
    "df_data.ref_count = df_data.ref_count.apply(lambda x: int(x) if not pd.isnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from the \"str\" type to the \"list\" type of some columns of Production data.\n",
    "df_data.replace({np.nan: None}, inplace=True)\n",
    "df_data.auth_keywords = df_data.auth_keywords.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_data.index_terms = df_data.index_terms.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_data.affiliations = df_data.affiliations.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_data.subject_areas = df_data.subject_areas.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_data.authors = df_data.authors.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_data.author_affil = df_data.author_affil.apply(lambda x: eval(x) if not pd.isnull(x) else None)\n",
    "df_data.references = df_data.references.apply(lambda x: eval(x) if not pd.isnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the \"members_name\" column and creating the \"number_members\" column for each work.\n",
    "df_data.members_name = [tuple(df_members.complete_name[\n",
    "        [len(set(ids).intersection(set([str(author[\"id\"]) for author in authors]))) > 0\n",
    "         for ids in df_members.identifiers.values]\n",
    "].values) for authors in df_data.authors.values]\n",
    "\n",
    "df_data[\"number_members\"] = [df_members.complete_name[\n",
    "        df_members.complete_name.isin(member) & df_members.is_permanent].size\n",
    "                for member in df_data.members_name.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the country for the brazilian affiliations without this feature.\n",
    "ids = [\"0031104541\", \"26944494548\", \"51749115113\", \"67649946788\",\n",
    "       \"39749115635\", \"77952509269\"]\n",
    "df_data.affiliations[df_data.id.isin(ids)] = [tuple([{**affil, \"country\": \"Brazil\"} \\\n",
    "       if not affil[\"country\"] else affil for affil in affils])\n",
    "    for affils in df_data.affiliations[df_data.id.isin(ids)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicated authors within the same record.\n",
    "df_data.author_affil[df_data.id == \"33845809181\"] = df_data.author_affil[\n",
    "    df_data.id == \"33845809181\"].apply(lambda x: x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the correct affiliation for record whose id is \"79955775766\".\n",
    "df_data.author_affil[df_data.id == \"79955775766\"] = df_data.author_affil[\n",
    "    df_data.id == \"79955775766\"].apply(lambda x: tuple([*x[:2], x[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the correct affiliation for record whose id is \"85020791355\".\n",
    "df_data.affiliations[df_data.id == \"85020791355\"] = df_data.affiliations[\n",
    "    df_data.id == \"85020791355\"].apply(lambda x: tuple([*df_data.affiliations[\n",
    "        df_data.id == \"84947312273\"].iloc[0], {\"id\": \"60010758\",\n",
    "        \"affiliation\": \"Université de Mons\", \"country\": \"Belgium\"}]))\n",
    "df_data.author_affil[df_data.id == \"85020791355\"] = df_data.loc[df_data.id == \"85020791355\",\n",
    "    [\"affiliations\", \"author_affil\"]].apply(lambda row: tuple([\n",
    "        {**author, \"affil_id\": str(row.affiliations[0][\"id\"]) \\\n",
    "            if author[\"affiliation\"] == \"UFRN\" else str(row.affiliations[1][\"id\"])}\n",
    "        for author in row.author_affil]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the correct affiliation for record whose id is \"85026837976\".\n",
    "df_data.author_affil[df_data.id == \"85026837976\"] = df_data.author_affil[\n",
    "    df_data.id == \"85026837976\"].apply(lambda x: tuple([*x[:3], *[{**affil,\n",
    "        \"affil_id\": \"60011324\"} for affil in x[3:]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the correct affiliation for record whose id is \"0036949197\".\n",
    "temp = [{\"id\": \"60003709\", \"affiliation\": \"Universidade Federal de Campina Grande\",\n",
    "    \"country\": \"Brazil\"}, {\"id\": \"60011324\", \"affiliation\": \"Universidade Federal da Paraiba\",\n",
    "    \"country\": \"Brazil\"}]\n",
    "df_data.affiliations[df_data.id == \"0036949197\"] = df_data.affiliations[\n",
    "    df_data.id == \"0036949197\"].apply(lambda x: tuple([*x, *temp]))\n",
    "temp = {\"56249460300\": \"60011324\", \"7202634615\": \"60003709\", \"7201494953\": \"60011324\"}\n",
    "df_data.author_affil[df_data.id == \"0036949197\"] = df_data.author_affil.loc[\n",
    "    df_data.id == \"0036949197\"].apply(lambda x: tuple([*x[:4], *[{**affil,\n",
    "        \"affil_id\": temp[str(affil[\"id\"])]} for affil in x[4:]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the correct affiliation for record whose id are \"85043396160\", \"0032302636\", \"85114962520\".\n",
    "temp = {\"id\": \"60023857\", \"affiliation\": \"Universidade Federal do Rio Grande do Norte\", \"country\": \"Brazil\"}\n",
    "df_data.affiliations[df_data.id.isin([\"85043396160\", \"0032302636\", \"85114962520\"])] = df_data.affiliations[\n",
    "    df_data.id.isin([\"85043396160\", \"0032302636\", \"85114962520\"])].apply(\n",
    "        lambda x: tuple([affil if str(affil[\"id\"]) not in {\"112589976\", \"126896742\"} \\\n",
    "            else temp for affil in x]))\n",
    "temp = {\"112589976\": \"60023857\", \"126896742\": \"60023857\"}\n",
    "df_data.author_affil[df_data.id.isin([\"85043396160\", \"0032302636\", \"85114962520\"])] = df_data.author_affil.loc[\n",
    "    df_data.id.isin([\"85043396160\", \"0032302636\", \"85114962520\"])].apply(lambda x: tuple([{**affil,\n",
    "        \"affil_id\": temp[str(affil[\"affil_id\"])] if str(affil[\"affil_id\"]) in temp else str(affil[\"affil_id\"])}\n",
    "            for affil in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the list of authors and their affiliations for record whose id is \"84942546461\".\n",
    "temp = {\"id\": \"57040578700\", \"name\": \"Ádller De O. Guimarães\"}\n",
    "df_data.authors[df_data.id == \"84942546461\"] = df_data.authors[\n",
    "    df_data.id == \"84942546461\"].apply(lambda x: tuple([*x[:2], temp]))\n",
    "temp = {**temp, \"affil_id\": None, \"affiliation\": None, \"country\": None}\n",
    "df_data.author_affil[df_data.id == \"84942546461\"] = df_data.author_affil[\n",
    "    df_data.id == \"84942546461\"].apply(lambda x: tuple([*x[:3], *[{**temp,\n",
    "        \"affil_id\": affil} for affil in [\"60023857\", \"114536011\"]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the correct affiliation for the some records.\n",
    "df_data.author_affil[df_data.id == \"84867959509\"] = df_data.author_affil[\n",
    "    df_data.id == \"84867959509\"].apply(lambda x: tuple([*x[:-1], {**x[-1],\n",
    "        \"affil_id\": str(x[-2][\"affil_id\"]), \"affiliation\": x[-2][\"affiliation\"],\n",
    "        \"country\": x[-2][\"country\"]}]))\n",
    "df_data.author_affil[df_data.id == \"22744442063\"] = df_data.author_affil[\n",
    "    df_data.id == \"22744442063\"].apply(lambda x: tuple([*x[:2], {**x[2],\n",
    "        \"affil_id\": \"60003709\"}, *x[3:6], {**x[6], \"affil_id\": \"60003709\"}]))\n",
    "df_data.author_affil[df_data.id == \"85081616543\"] = df_data.author_affil[\n",
    "    df_data.id == \"85081616543\"].apply(lambda x: tuple([*x[:-2],\n",
    "        *df_data.author_affil[df_data.id == \"85081591459\"].item()[-2:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the correct affiliation for the some records.\n",
    "ids = [\"84920913312\", \"85050497831\"]\n",
    "df_data.affiliations[df_data.id.isin(ids)] = df_data.affiliations[\n",
    "    df_data.id.isin(ids)].apply(lambda x: df_data.affiliations[\n",
    "        df_data.id == \"84947312273\"].item())\n",
    "df_data.author_affil[df_data.id.isin(ids)] = df_data.loc[df_data.id.isin(ids),\n",
    "    [\"affiliations\", \"author_affil\"]].apply(lambda row: tuple([\n",
    "        {**author, \"affil_id\": str(row.affiliations[0][\"id\"])}\n",
    "        for author in row.author_affil]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the editor from the list of authors.\n",
    "temp = [\"56028680000\", \"35732489900\"]\n",
    "ids = [\"85062323680\", \"84927799972\"]\n",
    "df_data.author_affil[df_data.id.isin(ids)] = df_data.author_affil[\n",
    "    df_data.id.isin(ids)].apply(lambda x: tuple(\n",
    "        [auth for auth in x if str(auth[\"id\"]) not in temp]))\n",
    "df_data.authors[df_data.id.isin(ids)] = df_data.authors[\n",
    "    df_data.id.isin(ids)].apply(lambda x: tuple(\n",
    "        [auth for auth in x if str(auth[\"id\"]) not in temp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the alternative identifier to the affiliations without their IDs or the null ones.\n",
    "idx = list(set([idx for idx, row in df_data.author_affil[df_data.author_affil.notnull()].iteritems()\n",
    "                for item in row if not eval(str(item[\"affil_id\"]))]))\n",
    "df_data.author_affil[idx] = [\n",
    "    tuple([{**affil, \"affil_id\": str(hash(affil[\"affiliation\"])) \\\n",
    "                if not eval(str(affil[\"affil_id\"])) and affil[\"affiliation\"] else \\\n",
    "                eval(str(affil[\"affil_id\"])) if not eval(str(affil[\"affil_id\"])) and not affil[\"affiliation\"] \\\n",
    "                else affil[\"affil_id\"]} for affil in row])\n",
    "    for row in df_data.author_affil[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the \"normalize_affiliations\" function to the data.\n",
    "df_data[[\"affiliations\", \"author_affil\"]] = df_data[\n",
    "    [\"affiliations\", \"author_affil\"]].apply(normalize_affiliations, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates within the list of affiliations and authors.\n",
    "df_data.author_affil = [\n",
    "    set([(str(au[\"id\"]), au[\"name\"], str(au[\"affil_id\"]),\n",
    "        au[\"affiliation\"], au[\"country\"]) for au in row]) if row else None\n",
    "    for row in df_data.author_affil]\n",
    "df_data.author_affil = [tuple([dict(zip(\n",
    "        [\"id\", \"name\", \"affil_id\", \"affiliation\", \"country\"], au)) for au in row]) if row else None\n",
    "    for row in df_data.author_affil]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the \"normalize_name_authors\" function to the data.\n",
    "df_data[[\"authors\", \"author_affil\"]] = df_data[[\"authors\", \"author_affil\"]].apply(\n",
    "    normalize_name_authors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the \"normalize_features\" function to the data.\n",
    "df_data[[\"authors\", \"affiliations\", \"author_affil\"]] = df_data[\n",
    "    [\"authors\", \"affiliations\", \"author_affil\"]].apply(\n",
    "        normalize_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the \"year\" column from the \"publication_date\" column.\n",
    "df_data[\"year\"] = pd.DatetimeIndex(df_data.publication_date).year\n",
    "\n",
    "# Defining the \"month\" column from the \"publication_date\" column.\n",
    "df_data[\"month\"] = pd.DatetimeIndex(df_data.publication_date).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the members' h-index from their production.\n",
    "df_members[\"h_index\"] = df_members.complete_name.apply(lambda x: hindex(\n",
    "    df_data.citation_num[[x in members for members in df_data.members_name]].values))\n",
    "\n",
    "# Creating the members' g-index from their production.\n",
    "df_members[\"g_index\"] = df_members.complete_name.apply(lambda x: gindex(\n",
    "    df_data.citation_num[[x in members for members in df_data.members_name]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the h2-index of research group.\n",
    "df_members[\"h2_index\"] = hindex(df_members.h_index[df_members.is_permanent].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the \"normalize_id_features\" function to the data.\n",
    "df_data[[\"authors\", \"affiliations\", \"author_affil\", \"subject_areas\", \"references\"]] = df_data[\n",
    "    [\"authors\", \"affiliations\", \"author_affil\", \"subject_areas\", \"references\"]].apply(\n",
    "        normalize_id_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the analysis' period.\n",
    "period = list(range(2010, 2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data.\n",
    "df_data = df_data[df_data.year.isin(period)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fixing the inconsistences of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dictionary with the old and new ISSNs.\n",
    "issn = {\"07168756\": \"07180764\", \"14148862\": \"1984557X\", \"01959271\": \"18666892\",\n",
    "        \"0103944X\": \"19834071\", \"16875877\": \"16875869\", \"1558187X\": \"00189375\",\n",
    "        \"16784804\": \"01046500\", \"09746870\": \"09713514\", \"10459227\": \"2162237X\",\n",
    "        \"16875249\": \"16875257\", \"14148862\": \"1984557X\", \"23203765\": \"22788875\",\n",
    "        \"23090413\": \"03757765\", \"21791073\": \"21791074\", \"17518644\": \"17518652\",\n",
    "        \"15498328\": \"15580806\", \"19374208\": \"08858977\", \"18070302\": \"01018205\",\n",
    "        \"19842538\": \"1984252X\", \"15730484\": \"09208542\", \"15728080\": \"09295585\",\n",
    "        \"19255810\": \"14801752\", \"14698668\": \"02635747\", \"01034308\": \"21752745\",\n",
    "        \"07437315\": \"10960848\", \"15730409\": \"09210296\", \"10947167\": \"15411672\",\n",
    "        \"23174609\": \"23190566\", \"16155297\": \"16155289\", \"2195268X\": \"21952698\",\n",
    "        \"16779649\": \"22366733\", \"10834419\": \"21682267\", \"19430671\": \"19430663\",\n",
    "        \"1558187X\": \"00189375\", \"11092777\": \"22242678\", \"16771966\": \"21798451\",\n",
    "        \"16875257\": \"16875249\", \"15167399\": \"21791074\", \"15173151\": \"24464740\",\n",
    "        \"13502379\": \"17518652\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the old ISSN to the new ISSN.\n",
    "for issn_old, issn_new in issn.items():\n",
    "    df_data.issn.loc[df_data.issn.notnull() & df_data.issn.str.contains(issn_old, na=False) &\n",
    "                     ~df_data.issn.str.contains(issn_new, na=False)] = df_data.issn.loc[\n",
    "                     df_data.issn.notnull() & df_data.issn.str.contains(issn_old, na=False) &\n",
    "                     ~df_data.issn.str.contains(issn_new, na=False)].apply(\n",
    "                         lambda x: \"{} {}\".format(x, issn_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the production data.\n",
    "columns = [\"members_name\", \"id\", \"title\", \"abstract\", \"citation_num\", \"auth_keywords\", \"index_terms\",\n",
    "           \"vehicle_name\", \"affiliations\", \"subject_areas\", \"authors\", \"author_affil\",\n",
    "           \"year\", \"month\", \"ref_count\", \"references\"]\n",
    "df_data[columns].to_csv(\"../data/prepared/production_members_final.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Saving the members' data.\n",
    "columns = [\"complete_name\", \"identifiers\", \"h_index\", \"is_permanent\", \"research_line\", \"subject_areas\",\n",
    "           \"citation_count\", \"document_count\", \"coauthor_count\", \"affiliation_current\", \"affiliation_history\"]\n",
    "df_members[columns].to_csv(\"../data/prepared/members_stats_final.csv\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e313781e5f9487634688338feaea31cdeb3d0e175705036a80436c634137acb0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
