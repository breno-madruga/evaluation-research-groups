{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVJgbbbtmZGW"
   },
   "source": [
    "# Generating CNA metrics datasets from collaboration nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CprkkUhSmZGX"
   },
   "source": [
    "## 1. Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1778,
     "status": "ok",
     "timestamp": 1610753959648,
     "user": {
      "displayName": "BRENO SANTOS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrnybjWan0DPVsU6jccUngT6cCaHISyB6ONi5X=s64",
      "userId": "11680822205897604923"
     },
     "user_tz": 180
    },
    "id": "ZVNCRW4YmZGZ"
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries.\n",
    "import csv, pandas as pd, networkx as nx, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_efUuqaRPld"
   },
   "source": [
    "## 2. Getting and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the metrics of research group.\n",
    "def get_records_per_metric(metric_name, metric_per_nodes, nodes_attributes):\n",
    "    records = []\n",
    "    for id, metric in metric_per_nodes.items():\n",
    "        record = {}\n",
    "        record[\"id\"] = id\n",
    "        record[\"metric_value\"] = metric\n",
    "        record[\"metric_name\"] = metric_name\n",
    "        record[\"complete_name\"] = nodes_attributes[id][\"complete_name\"]\n",
    "        record[\"h_index\"] = nodes_attributes[id][\"h_index\"]\n",
    "        record[\"is_permanent\"] = nodes_attributes[id][\"is_permanent\"]\n",
    "        record[\"research_line\"] = nodes_attributes[id][\"research_line\"] if record[\"is_permanent\"] else None\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values(\"complete_name\")\n",
    "\n",
    "def get_metrics_complete(networks, year_papers, name_dataset):\n",
    "    list_result = []\n",
    "    for net in networks:\n",
    "        df_result = pd.DataFrame()\n",
    "        G = nx.read_gexf(net)\n",
    "        temp = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "        metrics = {\"degree\": nx.degree_centrality(G),\n",
    "                   \"betweenness\": nx.betweenness_centrality(G, normalized=True, weight=\"num_paper\"),\n",
    "                   \"eigenvector\": nx.eigenvector_centrality(G, max_iter=2000, weight=\"num_paper\"),\n",
    "                   \"closeness\": nx.closeness_centrality(G, distance=\"num_paper\", wf_improved=True),\n",
    "                   \"clustering\": nx.clustering(G, weight=\"num_paper\"),\n",
    "                   \"num_cliques\": nx.number_of_cliques(G),\n",
    "                   \"eccentricity_scc\": nx.eccentricity(temp)\n",
    "        }\n",
    "        for metric_name, metric_values in metrics.items():\n",
    "            records = get_records_per_metric(metric_name, metric_values, dict(\n",
    "                G.nodes(data=True) if not metric_name == \"eccentricity_scc\" else temp.nodes(data=True)))\n",
    "            df_result = pd.concat([df_result, records], ignore_index=True)\n",
    "        df_result.loc[:, \"year\"] = net.split(\"/\")[-1].split(\"_\")[0]\n",
    "        if \"window\" in net:\n",
    "            step = int(net.split(\"/\")[-1].split(\"_\")[-2])\n",
    "            step -= 1\n",
    "        else:\n",
    "            step = None\n",
    "        df_result.loc[:, \"total_num_paper\"] = year_papers[year_papers == int(df_result.loc[0, \"year\"]) \\\n",
    "            if \"cumulative\" not in net else \\\n",
    "            year_papers <= int(df_result.loc[0, \"year\"]) \\\n",
    "            if pd.isnull(step) else \\\n",
    "            (year_papers >= int(df_result.loc[0, \"year\"]) - step) & (year_papers <= int(df_result.loc[0, \"year\"]))].count()\n",
    "        records = df_result[df_result.metric_name == \"eccentricity_scc\"].copy()\n",
    "        records.loc[:, \"metric_name\"] = \"eccentricity_scc_normed\"\n",
    "        records.loc[:, \"metric_value\"] = records[\"metric_value\"] / temp.number_of_nodes() - 1\n",
    "        df_result = pd.concat([df_result, records], ignore_index=True)\n",
    "        list_result.append(df_result.copy())\n",
    "\n",
    "    pd.concat(list_result, ignore_index=True).to_csv(name_dataset, index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data.\n",
    "df_data = pd.read_csv(\"../data/prepared/production_members_final.csv\", header=0, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data.\n",
    "df_data = df_data[[\"members_name\", \"year\"]]\n",
    "df_data.members_name = df_data.members_name.apply(lambda x: eval(x) if x else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating and saving the CNA metrics datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2426,
     "status": "ok",
     "timestamp": 1610753962199,
     "user": {
      "displayName": "BRENO SANTOS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrnybjWan0DPVsU6jccUngT6cCaHISyB6ONi5X=s64",
      "userId": "11680822205897604923"
     },
     "user_tz": 180
    },
    "id": "xpKQ9xXYmZGp"
   },
   "outputs": [],
   "source": [
    "# Getting the metrics.\n",
    "networks = sorted(glob.glob(\"../data/networks/*network.gexf\"))\n",
    "get_metrics_complete(networks, df_data.year, \"../data/prepared/metrics_isolated.csv\")\n",
    "\n",
    "networks = sorted(glob.glob(\"../data/networks/*network_cumulative.gexf\"))\n",
    "get_metrics_complete(networks, df_data.year, \"../data/prepared/metrics_cumulative.csv\")\n",
    "\n",
    "networks = sorted(glob.glob(\"../data/networks/*network_cumulative*_4_window.gexf\"))\n",
    "get_metrics_complete(networks, df_data.year, \"../data/prepared/metrics_cumulative_4_window.csv\")\n",
    "\n",
    "networks = sorted(glob.glob(\"../data/networks/*network_cumulative*_2_window.gexf\"))\n",
    "get_metrics_complete(networks, df_data.year, \"../data/prepared/metrics_cumulative_2_window.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNA.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('research_group')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "cdabaff41c382772809d94cc343ca9a6e188a976237c70fd0bafa0cf08e3c91a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
